\section{Skipping Lean's parser}

The main bottleneck on the performance of our tool is the parsing
of the proof by Lean. The flag \texttt{--profile} from
Lean's compiler can be used to indicate how much time was spent on each
process during the checking of a proof. The tests we did with
this flag pointed out that over 90\% of the time was spent
during parsing. Therefore, if the Lean's parser were skipped we could
increase the speed of the reconstruction of proofs.

This could be done by modifying
cvc5's printer, so that it prints terms in an intermediate format
that is similar to the internal representation used by Lean (i.e.
with the type \texttt{Expr}). Then, the proof format would be changed
to a list containing the steps of the proof. Each step would be
represented by the name of a theorem or tactic, the arguments passed to it and the expected return type, printed in
this new intermediate format. Also, it would be necessary to implement
a lightweight parser in Lean for this proof format. Clearly, this parser
would be much simpler than Lean's. Since our tactics are implemented
using the \texttt{MetaM} monad, this optimization would completely
remove any calls to Lean's parser in our tool.

\section{Naming shared terms}

Another factor that contributes to reduce performance is the size of
the proof scripts. Frequently, the same expression is printed multiple
times across the proofs. One simple way to reduce the size of the
scripts is to define macros for any expression whose abstract syntax
tree has a depth greater than 1. By printing the macros instead
of the expressions themselves, the proof will not have any
term whose depth is greater than 1, potentially leading to
an exponential reduction in its size.

\section{Parsing other proof formats}

Currently, our framework for proof reconstruction only supports
proofs generated in the format produced by cvc5 that we have shown.
Therefore, it can only verify cvc5 proofs. By implementing a
parser for other proof formats (such
as the Alethe format~\cite{alethe}) we could reconstruct proofs
generated by any solver that supports these formats.
This would also increase the potential of the tool as a hammer,
since it will enable the possibility of using different solvers,
which have different strengths, to search for proofs for a given
goal.


\section{Supporting new theories}

We have implemented proof reconstruction for Boolean,
Equality and Linear Arithmetic reasoning. SMT solvers
also support a variety of other theories that would be interesting
to include in our framework. One interesting addition would be the theory of
\textit{Bitvectors}, that is, arrays of bits, which capture
the semantics of machine integers and are ubiquitous on formalizations
of implementations of algorithms and data structures. Also,
some SMT solvers (in particular, cvc5~\cite{quantElim}) support
reasoning over formulas involving quantifiers. This kind of
formulas are much more expressive than the ones we are currently
supporting. Moreover, theorems proven in ITPs frequently involve
quantifiers. Therefore, adding support for quantifier reasoning
in our framework would be very useful.

Supporting these theories would require writing new
theorems and tactics matching their rules and extending the
printer to use these theorems and tactics in the produced scripts.

\section{Proper evaluation}

We also intend to do a proper evaluation of our tool, following the format done by~\cite{carcara}. In particular, we would like to
analyze which tactics are being used more frequently and
should be targets for optimization. It would also be interesting
to compare our tool to one that just performs proof checking
independently of an ITP, such as~\cite{carcara}. This would provide
an accurate parameter for evaluating whether our tool has a good
performance.
