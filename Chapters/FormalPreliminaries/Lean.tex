\tom{disclaimer: for now I will just give a minimal definition on Lean's features. Later, if I discover that I need something else in the next chapter I add it here}

Lean is both an Interactive Theorem Prover and a programming
language. It is based on the Calculus of Inductive Constructions (CIC)~\cite{cic_ref} and explores the well-known correspondence between types and propositions~\cite{ch_correspondence} to implement a system that is both a proof checker and a type checker. This way, the ITP has a kernel with less than 7500 lines\footnote{Information obtained in 25/07/2023} that is powerful enough to recognize a language capable of expressing the theory of dependent types~\cite{dep_type_theory}.

\subsection{Lean as a Programming Language}

Lean has all the main features one can expect from a functional programming language. Its features include algebraic datatypes, pattern matching, polymorphism, typeclasses, IO support using monads and a robust macro system. The following script is a valid Lean program, that defines a new type representing natural numbers, together with a function for adding them:

\begin{minted}{lean}
inductive Natural where
  | zero : Natural
  | succ : Natural -> Natural

open Natural

def add (n m : Natural) : Natural :=
  match n with
  | zero    => m
  | succ n' => succ (add n' m)

notation x " + " y => add x y
\end{minted}

The keyword \textit{inductive} is used to introduce a new type, which in this case will be named \textit{Natural}. After the name, the user must use the keyword \textit{where}, followed by its constructors and their types. The constructors for the type Natural are \textit{zero} (which does not take any parameter and returns a Natural) and \textit{succ} (which takes a Natural and returns another one). This declaration introduces the constructors in the context with the names \textit{Natural.zero} and \textit{Natural.succ}. In order to be able to write just ``zero'' and ``succ'' we use the command \textit{open Natural}.

The next three lines define the sum function. We define new functions using the keyword \textit{def} followed by its name, the list of parameters and their types, the return type and the body of the function after the symbol ``:=''. In this case, we define the function by pattern matching on the first parameter. If it is \textit{zero}, we just return the second parameter. If it is \textit{succ} of some other value \textit{n'}, we return the \textit{succ} constructor applied to the result of a recursive call of \textit{add}, using \textit{n'} and \textit{m}.

Lastly, we use the command \textit{notation} to define a macro for using the add function with the usual infix ``+'' operator.

% Another useful feature of Lean is the possibility of asking for a type of a given expression. We do this with the command \textit{\#check}, followed by the expression we want to consult the type:

% \begin{minted}{lean}
%   #check add -- Natural -> Natural -> Natural
%   #check Natural -- Type
% \end{minted}

\subsection{Lean as a Theorem Prover}

In Lean, propositions are represented by types, which are inhabited by terms that represent proofs of those propositions. For instance, the following Lean expression represents a proposition (which is also a type) stating that, according to our previous definition of natural numbers, the addition of any natural \textit{n} and \textit{zero} results in \textit{n}:

\begin{minted}{lean}
∀ (n : Natural), (n + zero) = n
\end{minted}

The representation of this predicate as a type is possible due to the fact that Lean supports dependent types, that is, types that depend on values of other types. The operator \textit{=} in this expression is a type constructor that accepts two values of the same type.

Therefore, proving that this statement holds amounts to finding a term with this type. The following snippet shows the construction of such term:

\begin{minted}{lean}
theorem add_zero : ∀ (n : Natural), (n + zero) = n :=
  fun n =>
    match n with
    | zero    => rfl
    | succ n' => congrArg succ (add_zero n')
\end{minted}

This structure follows the same pattern as the one for defining functions, the only difference is the change of the keyword \textit{def} to \textit{theorem}. After the symbol ``:='' we have essentially a constructive proof of the statement. First, it introduces the variable binded by the $\forall$ symbol in the context, using \textit{fun n}. Then, it uses pattern match on \textit{n}. If \textit{n} is \textit{zero}, the type that is required is reduced to \textit{zero + zero = zero}, which follows directly from the definition of \textit{add}. The term \textit{rfl} is a proof that any term is equal to itself. In this case, Lean can match its type with the required one. If \textit{n} follows the pattern \textit{succ n'}, then the required type is \textit{succ n' + zero = succ n'}. By the definition of \textit{add}, the left-hand side evaluates to \textit{succ (n' + zero)}.
Note that the term \textit{add\_zero n'} has type \textit{n' + zero = n'}, which is almost the required one, missing only the \textit{succ} on both sides. This is solved by applying \textit{congrArg succ} on \textit{add\_zero n'} (\textit{congrArg} is a version of Theorem~\ref{cong_theorem} in Lean's library), which produces a term with the correct type.


We also present a proof that our addition function is commutative, together with another necessary lemma:

\begin{minted}{lean}
  theorem add_succ : ∀ (n m : Natural),
    (n + succ m) = succ (n + m) := fun n m =>
  match n with
  | zero    => rfl
  | succ n' => congrArg succ (add_succ n' m)

theorem add_comm : ∀ (n m : Natural), (n + m) = (m + n) := fun n m =>
  match n with
  | zero    => Eq.symm (add_zero m)
  | succ n' =>
    Eq.trans (congrArg succ (add_comm n' m)) (Eq.symm (add_succ m n'))
\end{minted}

Note that, since we have to make explicit every single logic step, even simple proofs are not easy to write and read. Lean (and most ITPs) provide an alternative for this kind of proof: the usage of tactics. As previously explained, tactics are routines that simulate common proof techniques. While we are building a proof term, Lean's kernel always keep track of a context, containing all declarations in scope and what is the currently expected type for the term we are building (also known as the goal). Tactics operate by manipulating these two structures, without compromising the trusted kernel. In other words, any modification that is made by a tactic must be properly justified and will be checked by Lean's kernel, in the same way it checked that our proof was correct.

We present a new version of \textit{add\_comm} with this new approach:

\begin{minted}{lean}
theorem add_comm' : ∀ (n m : Natural), (n + m) = (m + n) := by
  intros n m
  induction n with
  | zero       => rw [add, add_zero]
  | succ n' IH => rw [add, add_succ, IH]
\end{minted}

The keyword \textit{by} is used to communicate that the term will not be build explicitly, but instead computed by a sequence of tactics, also known as a tactic block. Given a goal of the form $\forall (x : t) . P(x)$, the tactic \textit{intros x} will change the goal to $P(x)$ and introduce in the context a variable with name $x$ and type $t$. It can also be used to introduce multiple variables at one. We use it to introduce two naturals, \textit{n} and \textit{m}. Next, we use the \textit{induction} tactic. This is a very general tactic that can apply the induction principle on any inductive type. Since our goal is of the form $P(n, m)$, where $n$ is a natural number, it will produce two new goals: $P(zero, m)$ and $P(n', m) \rightarrow P(succ(n'), m)$. Each one of this goals is then completed by the \textit{rw} tactic. Given a term that represents a proof of an equality $e_{1} = e_{2}$, the tactic \textit{rw} rewrites all occurrences of $e_{1}$ by $e_{2}$ in the goal. With this, we can avoid the usage of transitivity, symmetry and congruence lemmas that were needed on the other version of this proof. Note that this tactic also accepts function names such as \textit{add} as a parameter. In this case, it rewrites the definition of the function.

\subsection{Metaprogramming in Lean}

Lean has a metaprogramming framework that enable its users to implement new tactics. In our project, we heavily rely on this framework for translating the SMT solver's logical rules, as demonstrated later. We will provide a concise overview of the tactic implementation process in Lean. For a more comprehensive guide, refer to~\cite{metaLean}.

\subsubsection{Expr}

% important things to say:
% \begin{itemize}
%   \item DONE expr is the internal representation of any lean expression used by the compiler
%   \item DONE tactics manipulate them directly
%   \item DONE basic overview on how they are structured - show real AST hiding irrelevant parts
%   \item TODO they go to the kernel to be checked
%   \item TODO the goal of a tactic is often produce an expr with the type of the goal
% \end{itemize}


In Lean, the development of tactics relies on metaprogramming principles. These routines are allowed to access and manipulate terms using the internal representation employed by the compiler, granting them a lot of flexibility. Therefore, to understand how tactics operate it is important to understand how the compiler abstracts the structure of programs.

Terms (both values and types) are internally represented through its abstract syntax tree, which is modeled by the built-in type \textit{Expr}. The following code shows a simplified version of the declaration of this type, omitting some specific parts that are not important in the context of this work (we also omit such parts in the examples we give):

\tom{hiding Levels... is it okay? they are not directly needed to understand our tactics and I don't really understand them completely}
\begin{minted}{lean}
inductive Expr where
| bvar    : Nat -> Expr
| fvar    : FVarId -> Expr
| mvar    : MVarId -> Expr
| const   : Name -> Expr
| app     : Expr -> Expr -> Expr
| lam     : Name -> Expr -> Expr -> Expr
| forallE : Name -> Expr -> Expr -> Expr
\end{minted}

\tom{too similar to the metaprogramming book?}
This type can be understood as an extension of the abstract syntax tree of terms in Lambda Calculus~\cite{lcIntro}. The language structures that match each one of these constructors are given as follows:
\begin{itemize}
  \item \textbf{bvar} (bounded variable): variables bounded by a lambda or a quantifier, such as the second \textit{n} in \tom{I don't know if I should use minted or textit here} \mintinline{lean}{∀ (n : Natural), (n + zero) = n}. The \textit{Nat} value they take as parameter is a natural number corresponding to their De Bruijn index~\cite{debruijnIndices}.
  \item \textbf{fvar} (free variable): variables that appear in an expression which are not bound by a binder. There must be a declaration in context assigning a value for them.  The parameter of their constructor (\textit{FVarId}) is an identifier for their declaration in the context. Unlike bounded variables, it is necessary to have access to the context to derive their type. The tactic \textit{intros} we described before transforms bound variables into free variables on the goal.
  \item \textbf{mvar} (metavariable): variables that have a type but were not assigned an expression corresponding to their value yet. Goals that were not closed yet, for instance, are represented as metavariables. The parameter of their constructor (\textit{MVarId}) is also an identifier for them in the context.
  \item \textbf{const} (constant): A constant value, previously declared. The \textit{Name} parameter in the constructor is the internal type that represents identifiers. The syntax \textit{\textasciigrave ident} creates a value of type \textit{Name} representing the identifier \textit{ident}. For instance, in the \textit{Natural} type we introduced, \textit{zero} is represented as \textit{const \textasciigrave zero}.
  \item \textbf{app} (function application): Usual function application, in the style of Lambda Calculus. \textit{succ (succ zero)} is represented as \textit{app (const \textasciigrave succ) (app (const \textasciigrave succ) (const \textasciigrave zero))}.
  \item \textbf{lam} (lambda abstraction): Usual lambda abstraction. The parameters represent: the name of the binded variable (used for pretty printing the expression); the type of the binded variable; and the body of the lambda expression.
  \item \textbf{forallE} (dependent arrow type): Used to represent types of functions. It also can express functions whose return type depend on the value it is given. This kind of type is also known as dependent arrows. The for all operator used before is a syntax sugar for a dependent arrow. For instance, \mintinline{lean}{∀ (n : Natural), (n + zero) = n} is the same as \mintinline{lean}{(n : Natural) -> n + zero = n}. The first parameter of the constructor is the name of the variable in the type of the domain of the function (\textit{n} in our example), the second is its type (\textit{Natural} in our example) and the third is the return type of the function (\textit{n + zero = n}) in our example. The return type can refer to the value in the domain type as \textit{bvar 0}.
\end{itemize}

The end goal of a tactic block is to produce an expression that matches the type required by the theorem. Hence, the process of developing tactics is fundamentally based on manipulating expressions.

After all metavariables of an expression are assigned, the expression is sent to the kernel to be checked. Therefore, any manipulation done by a tactic will be checked and has to be sound, which means that we are not increasing the trusted base by using tactics.

\subsubsection{Monad Stack (?) Metaprogramming API (?)}
