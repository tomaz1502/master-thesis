Given this framework for encoding MSFOL in Lean, our goal is to
modify its architecture so that the validity of the rules can be
checked by the kernel, and also, in a way that enables the proofs to refer
to native Lean values, as opposed to only values encoded by the
\texttt{term} type. In this section we describe our first attempt
to achieve this goal, which was using the certified transformations
approach, as described in the introduction.

\subsection{The Boolean Fragment}

Initially, we will limit ourselves to the fragment of MSFOL that
deals with Boolean values\footnote{The Boolean fragment of the
\emph{Core} theory in SMT-Lib, as defined in
\url{http://smtlib.cs.uiowa.edu/theories-Core.shtml}}. Once
we show how to lift this fragment, we will present a generalization
of our definitions that could potentially serve as a basis to lift
any theory from MSFOL.\
%
The first step is to define a function to map values from the \texttt{term} type
to the corresponding native value.

While designing this function, we had a
choice on which type from Lean we would use as a counterpart of \texttt{term}. The two
most suitable alternatives were the \texttt{Prop} and \texttt{Bool} types. The former, as
previously explained, is the type used to model all propositions in the language, while
the latter is the usual type of booleans inhabited by only two values: \texttt{true} and
\texttt{false}. The \texttt{Bool} type has the advantage of potentially not requiring the
\texttt{Classical} module, as it is possible to prove classical statements over them. On
the other hand, propositions in Lean are stated in terms of \texttt{Prop}s.
\tom{I'm not sure about the next statement} Although it is
possible to state them in terms of \texttt{Bool}s, it is not usual. Given that one of the
end goals of our project is to serve as part of a Lean hammer, it is more appropriate
to adopt the most commonly format used. With this in mind, we chose to use \texttt{Prop}.


Note that the term we will evaluate can contain free variables. For those, we will need an auxiliary interpretation function assigning concrete values to them.
Free variables are
identified by a \texttt{Nat} (the built-in Lean type for natural numbers), therefore, we can
represent this information as a function from \texttt{Nat} to
\texttt{Prop}:

\begin{minted}{lean}
  def Interpretation := Nat -> Prop
\end{minted}

With this definition, we can define our evaluation function:

\begin{minted}{lean}
  def evalTerm (I : Interpretation) (t : term) : Prop :=
    match t with
    | term.const   i  _  => I i
    | term.not     t1    => Not (evalTerm I t1)
    | term.and     t1 t2 => And (evalTerm I t1) (evalTerm I t2)
    | term.or      t1 t2 => Or (evalTerm I t1) (evalTerm I t2)
    | term.implies t1 t2 => (evalTerm I t1) -> (evalTerm I t2)
    | term.eq      t1 t2 => (evalTerm I t1) = (evalTerm I t2)
    | term.bot           => False
    | term.top           => True
    | _                  => False
\end{minted}

This function is matching each pattern for a \texttt{term} with the corresponding built-in operation over \texttt{Prop}, and using recursive calls of itself as arguments. If we find a \texttt{term} that is not in the fragment we are currently supporting we just return \texttt{False}. This could potentially lead to consistency issues if the input formula involved other fragments apart from Boolean. As we are limiting ourselves to this fragment, we will ignore this problem for now.

Notice how the \texttt{Interpretation} type we introduced, as well as the evaluation function, match the notions of interpretation and evaluation introduced in Section~\ref{sec:msfolHere}. Indeed, we can now define what it means for an interpretation to satisfy a \texttt{term} and what it means to be unsatisfiable:

\begin{minted}{lean}
  def satisfies (I : Interpretation) (t : term) : Prop :=
    evalTerm I t = True
  def unsatisfiable (t : term) : Prop :=
    ∀ (I : Interpretation), ¬ satisfies I t
\end{minted}

One important concept we need to define is what it means for a \texttt{term}
to follow logically from another, which is the primary relationship modeled
by the axioms presented previously.
%
If, for any fixed interpretation, the evaluation of a given \texttt{term} being true
implies in the evaluation of another \texttt{term} being true, then we can always
conclude the second one from the first. The following definition states this
relationship in Lean:

\begin{minted}{lean}
  def impliesIn (t1 t2 : term) : Prop :=
    ∀ (I : Interpretation),
      satisfies I t1 -> satisfies I t2
\end{minted}

Notice that we needed to use the same interpretation for both terms.
%
The application \texttt{impliesIn t1 t2} gives a precise meaning to \texttt{thHolds t1 -> thHolds t2} in terms of the logic used by Lean.

Since we are interested in proving the unsatisfiability of terms, we will always try to prove a goal of the form \texttt{impliesIn t bot}, for some term \texttt{t}. This would imply that for any interpretation \texttt{I}, we have \texttt{(evalTerm I t = True) -> False}, provided that there is no environment that validates the interpretation of \texttt{bot}. Note that this is equivalent to \texttt{unsatisfiable t}, given our previous definition of \texttt{unsatisfiable}.
With the above we can rephrase and prove the rules from the deep embedding using
\texttt{impliesIn}.
%
For instance, the representation of \texttt{notImplies1} show in Section~\ref{sec:gen-scripts} becomes:

\begin{minted}{lean}
  theorem notImplies1 : ∀ {t1 t2 : term},
      impliesIn (not (implies t1 t2)) t1
\end{minted}

We have proved some of the theorems used in the boolean fragment\footnote{Our proofs can be found at \url{https://github.com/tomaz1502/signatures/blob/smallCheckers/Cdclt/Lift/Other/PropsExample.lean}.}. Their proofs
were straightforward using classical reasoning.

Finally, we can state the theorem from Section~\ref{sec:gen-scripts} as
\texttt{impliesIn notModusPonens bot}, and prove it using almost\footnote{while the original proof used the most general form of resolution, we have restricted ourselves to prove the specific version of resolution that was applied in this proof.} the same
(rephrased) rules in the same order, which already achieves the goal
of checking the proof using Lean's kernel.

In order to apply the generated proof in terms native to the ITP, we need
to prove the following auxiliary theorem:

\begin{minted}{lean}
  theorem notFollowsBot : ∀ {t : term},
    impliesIn (not t) bot → ∀ {I : Interpretation}, evalTerm I t = True
\end{minted}

By applying it on the theorem generated by cvc5, we derive that, for any
interpretation \texttt{I}, \texttt{evalTerm I modusPonensEmbed} is equal
to \texttt{True}:

\begin{minted}{lean}
theorem modusPonensEqTrue: ∀ {I: Interpretation},
    evalTerm I modusPonensEmbed = True :=
  notFollowsBot cvc5_th0
\end{minted}

Now we can define the theorem corresponding to \texttt{cvc5\_th0} using
\texttt{Prop}s and prove it by applying \texttt{modusPonensEqTrue} to
the appropriate interpretation:

\begin{minted}{lean}
def modusPonens (P Q : Prop) : Prop := P → (P → Q) → Q

theorem modusPonensCorrect: ∀ (P Q: Prop), (modusPonens P Q) = True := by
  intros P Q
  exact @modusPonensEqTrue (fun id => if id == 1000 then P else Q)
\end{minted}

where the symbol \texttt{@} is used to make explicit all parameters
in the function after it. Using this interpretation, we indicate
that the term \texttt{p} in \texttt{modusPonensEmbed}
will be matched with the prop \texttt{P} (since the identifier of \texttt{p}
is 1000) and the term \texttt{q} will be matched with the prop \texttt{Q}.
The checker can now compute our evaluation function and
match its return value with \texttt{modusPonens P Q}, thus proving the theorem.

Therefore, we have shown how to lift the proofs produced by cvc5 into proofs
that refer directly to native Lean terms. In order to fully automate this
process, we would have to extend cvc5's module for printing proofs. It would
have to also print, for a given query, the theorem (and its proof, which is always
\texttt{notFollowsBot cvc5\_th0}) corresponding to \texttt{modusPonensEqTrue} for that query,
the representation of the query as a Lean term (which in this example was the term \texttt{modusPonens})
and the theorem that proves that the representation of the query is correct by instantiating the interpretation
properly (corresponding to \texttt{modusPonensCorrect}).
Since we changed our approach, this extension was not realized.

\subsection{Supporting Other Theories}

Supporting more theories from MSFOL requires extending the function \texttt{evalTerm},
as well as the \texttt{Interpretation} type we defined, to be able to return values
of multiple distinct types. One type safe way to achieve this in a language with
dependent types is through a \textit{sigma type}. A sigma type is a pair, in which
the type of the second element depends on the value of the first element. If
\texttt{T} is a type and \texttt{U} is a constructor with type
\texttt{T -> Type}, then \texttt{@Sigma T U} is the type
of pairs \texttt{⟨t, u⟩} such that \texttt{t} has type \texttt{T} and
\texttt{u} has type \texttt{U t}. Note that the first parameter of \texttt{Sigma}
can be inferred from the second, so it is given implicitly.

Let us define a function \texttt{evalSort} that maps the type \texttt{sort}
(corresponding to MSFOL's sorts in the deep embedding) to native Lean types
(which are represented by \texttt{Type}):

\begin{minted}{lean}
  def evalSort : sort -> Type := fun s =>
    match s with
    | arrow s1 s2 => evalSort s1 -> evalSort s2
    | boolSort => Prop
    | intSort => Int
    | _ => Prop
\end{minted}

We have matched the \texttt{arrow} sort with the arrow type used to build the type of
functions, \texttt{boolSort} with \texttt{Prop} and \texttt{intSort} with \texttt{Int}.
For giving support for further theories we have to extend this match statement,
matching the corresponding \texttt{sort} with a suitable type. Since one of the goals
of the project is to be a hammer, it is crucial to choose, for a given sort,
a corresponding type that is most commonly employed by Lean users, and also
has the same properties as the sort.

Now we can reformulate the \texttt{Interpretation} type, in a way that
it supports any type that is also supported by \texttt{evalSort}:

\begin{minted}{lean}
  def Interpretation := Nat → @Sigma sort evalSort
\end{minted}

Given an identifier, an interpretation must return a pair containing its sort
and its value. Note that, with this modification, the interpretation printed
by cvc5 would also need to print the sort of each term. For instance,
the interpretation used in the theorem \texttt{modusPonensCorrect} would have
to be rewritten as:

\begin{minted}{lean}
  def I : Interpretation := fun id =>
    if id == 1000 then
      ⟨ boolSort, P ⟩
    else ⟨ boolSort, Q ⟩
\end{minted}

We will also use a sigma type for defining the new version of \texttt{evalTerm}.
%
Since we are now supporting multiple types, we have to consider what to return
when the input \texttt{term} is ill-typed. One possibility could be to map these
terms to \texttt{False}, as we were doing with \texttt{term}s that were not supported
in the previous version of \texttt{evalTerm}. However, this approach would introduce
a logical inconsistency that would pose challenges to prove some of the rules.
For instance, one rule used by cvc5 is the elimination of double negation:

\begin{minted}{lean}
  theorem notNotElim : ∀ {t : term},
      impliesIn (not (not t)) t
\end{minted}

In order to prove it, we have to consider every possible pattern for \texttt{t}.
If \texttt{t} is not a valid boolean expression, then our evaluation function would
return \texttt{False} for the term \texttt{not t}, which would then force the
evaluation of \texttt{not (not t)} to return \texttt{True}. Since the premiss
is valid in this case, we would have to prove that the conclusion is also valid,
but the conclusion is not a boolean expression. Therefore, the only way to prove it
would be to change our predicate \texttt{satisfies} to accept terms that are not booleans.

Instead of following this approach, we decided to change the evaluation function to just not return
any value if the input term is ill-typed. The polymorphic \texttt{Option} type is used in Lean to
indicate the possible absence of a value, which is represented by \texttt{none}, one of its
constructors. The other constructor, \texttt{some}, receives, as a parameter, a single value
of the type that is used as a parameter to \texttt{Option}.
%
The following snippet shows the reformulated version of \texttt{evalTerm}.
We do not show the complete pattern matching for brevity, but all the other
patterns are implemented using the same structure:

\begin{minted}{lean}
  def evalTerm (I : Interpretation) (t : term) :
      Option (@Sigma sort interpSort) :=
    match t with
    | term.const   i  s  =>
      let ⟨ s', value ⟩ := I i
      if s' == s then some ⟨ s', value ⟩ else none
    | term.and     t1 t2 =>
      match evalTerm I t1, evalTerm I t2 with
      | some ⟨ boolSort, p1 ⟩, some ⟨ boolSort , p2 ⟩ =>
          some ⟨ boolSort, And p1 p2 ⟩
      | _,_ => none
    | _ => none
\end{minted}

We have also reformulated our \texttt{satisfies} predicate, in a way that
it also rejects any term whose evaluation is not a \texttt{Prop}:

\begin{minted}{lean}
  def satisfies (I : Interpretation) (t : term) : Prop :=
    match evalTerm I t with
    | some ⟨ boolSort, p ⟩ => p = True
    | _ => False
\end{minted}

The predicate \texttt{impliesIn} did not require any modification. With these
rephrased definitions we could define and prove new versions of
the theorems regarding the boolean fragment, certifying the validity of the
cvc5 rules over the reformulated version of our framework.

The next step we took was to try to state and prove theorems corresponding to the
axioms from the theory of equality and uninterpreted functions, which
was presented in Section~\ref{sec:euf}. Consider the \texttt{refl} axiom:

\begin{minted}{lean}
  theorem refl : ∀ {I : Interpretation} {t : term}, satisfies I (eq t t)
\end{minted}

If \texttt{t} is ill-typed, then the statement does not hold. This was not
a problem before because all previous axioms were implications in which
the term in the conclusion was a subexpression of the premiss. Therefore,
if the conclusion was ill-typed, the premiss was also, necessarily, ill-typed,
which made the implication true. In the case of \texttt{refl} and of
any other possible theorems that do not have premisses, we have to restrict it
to only refer to well-typed terms in order to make their statement true.

For that purpose, we have defined a new function \texttt{inferSort} that infers the sort of a term
or returns \texttt{none} if it is ill-typed.
This new function is essentially identical to
\texttt{evalTerm}, except that it only computes the first element of the pair.
Also, since the sort of a term is independent of the interpretation we use
to evaluate it, we do not need an interpretation as a parameter in this function.
Now we can make the statement in the theorem \texttt{refl} true by adding the hypothesis
\texttt{isSome (inferSort t) = true}, where \texttt{isSome} is:

\begin{minted}{lean}
  def isSome (opt : Option sort) : Bool :=
    match opt with
    | some _ => true
    | none   => false
\end{minted}

The introduction of this hypothesis creates a new requirement for applying
the theorem in a proof, that is, we have to provide a proof that \texttt{t} is well-typed.
If it is well-typed (which will always be the case as long
as there is no bug in the SMT solver), then Lean's kernel can evaluate
both functions \texttt{inferSort} and \texttt{isSome} and obtain \texttt{true},
and the proof that the term is well-typed follows by reflexivity. Deriving facts
from the evaluation of functions is a proof technique known as \textit{proof by reflection}.
This kind of proof transfer the cost of \textit{checking} the proofs to a cost of
normalizing terms. Unfortunately, as pointed out by~\cite{ringLean}, Lean's evaluator
is not optimized for performance, therefore, the necessity of proving that certain term are
well-typed would probably reduce the efficiency of our tool.

Another downside of this approach is the necessity of providing explicit proofs for the most
general case of all rules. Some of the rules, such as resolution and
\textit{factor} (which takes as premiss a clause and have as a conclusion the same clause, removing
all formulas that are duplicated) appear to lack any proofs that are not highly challenging to derive.
This difficulty is also recognized in~\cite[6]{snipe}:
\begin{quote}
  ``Indeed, the former [certified transformations] require we work only with the reified [meaning deeply embedded] syntax of the
  terms of CIC and even for a simple transformation, the proof of soundess is hard (thousands lines of code).''
\end{quote}

As we will see later, the second approach does not require to build all the proofs \textit{explicitly}.
For those reasons, we decided to change our approach.

% According to~\cite[6]{snipe},

% From leanRingCertifying.pdf (paper about extending ring tactic with certifying
% transformations):
% % \cite{ringLean}
% The ring exp tactic does not use reflection but directly constructs proof
% terms to be type checked by Lean’s kernel, as is typical for tactics in mathlib [10].
% Reflective tactics avoid the construction and checking of a large proof term by
% performing most computation during proof checking, running a verified pro-
% gram [2]. If the proof checker performs efficient reduction, this results in a sig-
% nificant speed-up of the tactic, at the same time as providing more correctness
% guarantees. Unfortunately, the advantages of reflection do not translate directly
% to Lean. Tactic execution in Lean occurs within a fast interpreter, while the
% kernel used in proof checking is designed for simplicity instead of efficient reduc-
% tion [3]. Achieving an acceptable speed for ring exp requires other approaches
% to the benefits that reflection brings automatically.

% \tom{evalterm will have to be evaluated during the checking of the proof produced by cvc5
%   thats a performance issue = references}

% \tom{factor and resolution and permutateOr are exceedingly hard to be proved. From snipe:
% In the work presented in this article, we follow the paradigm of certifying transformations.
% Indeed, the former require we work only with the reified syntax of the terms of CIC and even for
% a simple transformation, the proof of soundess is hard (thousands lines of code).}

% \tom{Haniel said that Chantal said that it is hard to maintain the verification, take a look at her papers}
