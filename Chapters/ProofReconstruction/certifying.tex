The second approach is based on an idea known as certifying
transformations, which consists of generating proofs on demand
and checking them every time the tool is invoked.
%
The specific manner in which we applied
this concept in our context was to develop a set of tactics matching
the rules present in cvc5's proof calculus.
A cvc5 proof is now represented by a sequence of applications of those tactics.
When we ask Lean's kernel to check the proof script, it will execute one by one
of the tactics. Each one of them will inspect the current context
and produce a proof term, corresponding to a proof of a specific
case of the rule represented by that tactic.
The checker will then verify the correctness of each proof, closing the original goal if
all checks were succesful.

Originally, we implemented all of our tactics using various features from
\texttt{TacticM}.
In this initial iteration, we built the \texttt{Syntax} representation of a proof for the targeted rule and then invoked \texttt{evalTactic} using this representation.
However, later on, we identified a potential enhancement (which will be described in Chapter~\ref{chap:future}, as it was not completely executed yet) that led us to reimplement the
core functionality of all our tactics exclusively within the \texttt{MetaM} monad. This
second implementation was successfully executed.
Since the \texttt{MetaM} monad do not have access to Lean's elaborator, we could not represent proofs using
\texttt{Syntax} anymore. Instead, we had to manually craft the \texttt{Expr} that proved each theorem.

Another important difference from the certified transformations approach is that we do not use the \texttt{term}
type anymore. The main reason for mapping MSFOL formulas to this inductive type
instead of native Lean expressions was the flexibility achieved by this representation.
While it is straightforward to define a function that inspects and manipulates the structure of
a \texttt{term} by pattern matching, there is no way to do the same for certain Lean types (\texttt{Prop}, for
instance) without recurring to metaprogramming. As we have shown in Section~\ref{sec:metaLean},
the metaprogramming context grants us access to the internal representation of any expression
through the \texttt{Expr} type, which can be inspected and manipulated in the same way
as \texttt{term}. Since the framework for writing tactics is based on metaprogramming, we
did not need to rely on the flexibility of the \texttt{term} type anymore. Therefore, we
have decided to not use the deep embedding anymore, and translate MSFOL formulas directly
to Lean expressions.

In the rest of this section we will give an overview of the implementation of each tactic.
We present their statement with the same format used in cvc5's documentation\footnote{The documentation of cvc5's rules can be found at:
  \url{https://cvc5.github.io/docs/cvc5-1.0.2/proofs/proof_rules.html}}, that is,
for a tactic that has a conclusion $\psi$, premisses $\psi_{1} \cdots \psi_{n}$ and
parameters $t_{1} \cdots t_{n}$, we will write:
\[
  \infer[]{\psi}{\psi_{1}, \cdots, \psi_{n} \mid t_{1}, \cdots, t_{n}}
\]

Notice that a large portion of the rules can be trivially proved using classical
reasoning. Instead of mapping those rules to tactics, we just proved them as theorems.
Those theorems will not be presented here. For a complete overview of the rules, their statement and whether they were implemented with a tactic or a
theorem, refer to Table~\ref{tab:rules}.

\subsection*{GroupClausePrefix\\\normalsize{Rule Statement:}}
\[
  \infer[]{(P_{1} \vee \cdots \vee P_{i}) \vee P_{i + 1} \vee \cdots \vee P_{n}}
    {P_{1} \vee \cdots \vee P_{n} \mid i}
\]

The first tactic we will present does not correspond to a rule from cvc5's proof
calculus. Instead, it is a custom tactic we created to facilitate the implementation
of the others.

The operator $\vee$ in Lean is right-associative. This means that an expression of the form
$P_{1} \vee P_{2} \vee \cdots \vee P_{n}$ is internally represented as
$P_{1} \vee (P_{2} \vee (\cdots \vee P_{n}))$.
Given a natural number \texttt{i} and a proof \texttt{pf}
of the validity of a clause, \texttt{groupClausePrefix pf, i} proves the same clause, with the
first \texttt{i} propositions grouped. This tactic employs the following two theorems:

\begin{itemize}
  \item \mintinline{lean}{orAssoc {A B C : Prop} : A ∨ B ∨ C → (A ∨ B) ∨ C}
  \item \mintinline{lean}{congOrLeft {A B C : Prop} (hyp : A → B) : C ∨ A → C ∨ B}
\end{itemize}

% Also, it will make use of the \texttt{apply} tactic. If the current goal is \texttt{Q}, and
% we have a proof \texttt{h} of \texttt{P → Q}, we can reduce the goal to \texttt{P} with
% \texttt{apply h}.

% Let's instantiate, in the theorem \texttt{orAssoc}, \texttt{A} to $P_{1}$, \texttt{B}
% to $P_{2} \vee \cdots \vee P_{i}$ and \texttt{C} to $P_{i + 1} \vee \cdots \vee P_{n}$. This will yield a proof of
% of $P_{1} \vee (P_{2} \vee \cdots \vee P_{i}) \vee P_{i + 1} \vee \cdots \vee P_{n} \rightarrow (P_{1} \vee \dots \vee P_{i}) \vee P_{i + 1} \vee \cdots \vee P_{n}$. Since
% the proof script is annotated with the type it expects from each tactic application,
% we can assume that the current goal is $(P_{1} \vee \cdots \vee P_{i}) \vee P_{i + 1} \vee \cdots \vee P_{n}$. Therefore, we can change the goal to $P_{1} \vee (P_{2} \vee \cdots \vee P_{i}) \vee P_{i + 1} \vee \cdots \vee P_{n}$ with \texttt{apply orAssoc} (Lean's kernel can infer what are the implicit arguments in this case). Now we would like to apply \texttt{orAssoc} again to remove $P_{2}$ from the parenthesized group. We cannot do it directly, due to the term $P_{1}$ to the left of the parenthesis. We solved this
% problem by using \texttt{congOrLeft}, with \texttt{C} instantiated to $P_{1}$ and
% \texttt{hyp} instantiated to \texttt{orAssoc}, which yields a proof of the correct
% statement. Therefore, we can change the goal to $P_{1} \vee P_{2} \vee (P_{3} \vee \cdots \vee P_{i}) \vee \cdots \vee P_{n}$ with \texttt{apply (congOrLeft orAssoc)}.

First, let's build a proof term for $P_{1} \vee \cdots \vee (P_{i - 1} \vee P_{i}) \vee \cdots \vee P_{n}$. We will instantiate, in \texttt{orAssoc}, the parameter \texttt{A} to $P_{i - 1}$, \texttt{B} to $P_{i}$ and \texttt{C} to $P_{i + 1} \vee \cdots \vee P_{n}$, obtaining the term:

\begin{center}
    $f_{1}: P_{i - 1} \vee P_{i} \vee \cdots \vee P_{n}   \rightarrow (P_{i - 1} \vee P_{i}) \vee \cdots \vee P_{n} $
\end{center}

Then, we apply \texttt{congOrLeft} to $f_{1}$ instantiating \texttt{C} to $P_{i - 2}$, which will produce:

\begin{center}
    $f_{2}: P_{i - 2} \vee P_{i - 1} \vee P_{i} \vee \cdots \vee P_{n}   \rightarrow P_{i - 2} \vee (P_{i - 1} \vee P_{i}) \vee \cdots \vee P_{n} $
\end{center}

We repeat this process until we get the term $f_{i - 1}$ of type $P_{1} \vee \cdots \vee P_{n} \rightarrow P_{1} \vee \cdots \vee (P_{i - 1} \vee P_{i}) \vee \cdots \vee P_{n}$. Applying $f_{i - 1}$ to our original hypothesis \texttt{h} will yield a term \texttt{h'} with type $P_{1} \vee \cdots \vee (P_{i - 1} \vee P_{i}) \vee \cdots \vee P_{n}$.

A clause is composed by any kind of propositions, including other clauses.
Therefore, the term $P_{1} \vee \cdots \vee (P_{i - 1} \vee P_{i}) \vee \cdots \vee P_{n}$ is a new clause
with $n - 1$ propositions, in which the $(i - 1)$-th proposition is the clause
$P_{i - 1} \vee P_{i}$. This means that our original problem can be reduced to
group the first $i - 1$ terms of this clause.
With this in mind, we repeat the process of composing \texttt{congOrLeft} with
\texttt{orAssoc} and apply the result to \texttt{pf'}, obtaining
a new term of type $P_{1} \vee \cdots \vee (P_{i - 2} \vee P_{i - 1} \vee P_{i}) \vee \cdots \vee P_{n}$.
We keep repeating this process until the whole prefix is grouped.


\begin{figure}[t]
\begin{minted}[linenos]{lean}
def groupPrefixCore (pf : Expr) (i : Nat) : MetaM Expr := do
  let clause  : Expr      ← inferType pf
  let props   : List Expr ← collectPropsInClause clause
  if i > 0 && i < List.length props then
    let lemmas : List Expr ← groupPrefixLemmas props (i - 1)
    let answer : Expr :=
      List.foldl (fun acc lem => Expr.app lem acc) pf lemmas
    return answer
  else throwError
    "[groupClausePrefix]: invalid prefix length"
\end{minted}
\caption{Implementation of the tactic GroupClausePrefix}\label{groupClause}
\end{figure}

The snippet in Figure~\ref{groupClause} was taken from the project's source code and shows the
implementation of the core functionality of this tactic.
The parameters \texttt{pf} and \texttt{i} of the function \texttt{groupPrefixCore}
represent, respectively, the proof of the validity of the original clause
and the length of the prefix that should be grouped. In line 2, we obtain
an \texttt{Expr} corresponding to the original clause by inspecting the type
of \texttt{pf}, with the built-in routine \texttt{inferType}. Then, in line 3,
we use the function \texttt{collectPropsInClause} (defined by us) to
extract a \texttt{List} with each one of the propositions in the clause.
Next, we check if the prefix length is valid. If it is, we apply the function
\texttt{groupPrefixLemmas} to obtain a list of expressions. Each element in this list
is a composition of \texttt{congOrLeft} and \texttt{orAssoc} described before.
Notice that we cannot rely on implicit parameters in the \texttt{Expr} level, so
this function also computes the implicit arguments that have to be
passed to \texttt{congOrLeft} and \texttt{orAssoc}. Lean has a built-in
functionality to automatically infer some of those arguments, but a significant
part of them have to be manually constructed. Finally, we use \texttt{foldl}
in line 7 to apply each one of the lemmas to \texttt{pf}, accumulating the results.

In order to use \texttt{groupPrefixCore} as a tactic, we also had to implement
a function of type \texttt{Syntax → TacticM Unit}, which parses the \texttt{Syntax}
to obtain \texttt{h} and \texttt{i} and use the \texttt{Expr} generated by
\texttt{groupPrefixCore} to close the current goal.

The following snippet shows an example of usage of this tactic:

\begin{minted}{lean}
  theorem group3 : A ∨ B ∨ C ∨ D ∨ E → (A ∨ B ∨ C) ∨ D ∨ E := by
    intro h
    groupClausePrefix h, 3
\end{minted}

We can use the \texttt{\#print} command to inspect the proof term generated by the tactic, and
verify that it is, indeed, the one we described:

\begin{minted}{lean}
  #print group3 -- fun {A B C D E} h => orAssoc (congOrLeft orAssoc h)
\end{minted}

\tom{proof term size is $\mathcal{O}(i^{2})$. Maybe say a few words about this?}

\subsection*{Pull\\\normalsize{Rule Statement:}}
\[
  \infer[]{A \vee P_{1} \vee \cdots \vee P_{i - 1} \vee P_{i + 1} \vee \cdots \vee P_{n}}{P_{1} \vee \cdots \vee P_{i - 1} \vee A \vee P_{i + 1} \vee P_{n} \mid A}
\]

Given a proof \texttt{pf} of the validity of a clause and a term $P_{i}$, this tactic should produce a proof term for the same clause,
with the first instance of $A$ in the clause moved to the first position. If there is no instance of $A$ in the clause, we throw an error
to notify the user. This tactic was also created to facilitate the implementation
of the other tactics and does not exist in cvc5's proof calculus. We will need three new theorems to implement \textit{pull}:

\begin{itemize}
  \item \mintinline{lean}{orComm {A B C : Prop} : A ∨ B → B ∨ A}
  \item \mintinline{lean}{congOrRight {A B C : Prop} (hyp : A → B) : A ∨ C → B ∨ C}
  \item \mintinline{lean}{orAssocConv {A B C : Prop} : (A ∨ B) ∨ C → A ∨ B ∨ C}
\end{itemize}

To build the required proof term, let's first search for the term we want to pull in the clause and calculate its index \texttt{i}. Then, we apply our tactic \texttt{groupClausePrefix} at \texttt{pf}, grouping the prefix of length \texttt{i - 1}.
We cannot use the tactic itself, as we are working on the context of \texttt{MetaM}, but we can invoke directly the function \texttt{groupPrefixCore}
to produce the required term. We will obtain the following term:

\begin{center}
  $pf_{1} : (P_{1} \vee \cdots \vee P_{i - 1}) \vee P_{i} \vee \cdots \vee P_{n}$
\end{center}

Then, we use again our function \texttt{groupPrefixCore} in \texttt{pf₁}, grouping the prefix of length 2. This will provide the term:

\begin{center}
  $pf_{2} : ((P_{1} \vee \cdots \vee P_{i - 1}) \vee P_{i}) \vee P_{i + 1} \vee \cdots \vee P_{n}$
\end{center}

Next, we will define a new term \texttt{pf₃} as \texttt{congOrRight orComm pf₂}. Given the appropriate instantiation for the implicit parameters,
this application flips the position of $P_{1} \vee \cdots \vee P_{i - 1}$ and $P_{i}$, while not modifying the suffix $P_{i + 1} \vee \cdots \vee P_{n}$.
Therefore, \texttt{pf₃} has type $(P_{i} \vee P_{1} \vee \cdots \vee P_{i - 1}) \vee P_{i + 1} \vee \cdots \vee P_{n}$ (we do not need to parenthesize
$P_{1} \vee \cdots \vee P_{i - 1}$ as $\vee$ is right-associative). Finally we use another tactic we implemented, \texttt{ungroupClausePrefix},
to remove the parenthesis around $P_{i} \vee P_{1} \vee \cdots \vee P_{i - 1}$, concluding our goal.
This tactic is very similar to \texttt{groupClausePrefix}. The
difference is that it substitutes the theorem \texttt{orAssoc} by \texttt{orAssocConv} and it applies the theorems in reverse order, i.e., it
starts with an application of \texttt{orAssocConv}, then it applies \texttt{congOrLeft orAssocConv} and so on.

One source of ambiguity that we have to take into account here is the representation of the clauses.
While there is no distinction in Lean between, for instance, the clauses $A \vee B \vee C \vee D \vee E$
and $A \vee B \vee C \vee (D \vee E)$, this distinction can be made inside the SMT solver. Indeed, if
we have a term \texttt{pf} in Lean of type $A \vee B \vee C \vee D \vee E$ and cvc5 prints the tactic
application \texttt{pull pf, 4}, there is no way to know, inside Lean, if it is expecting to receive
a proof of $D \vee A \vee B \vee C \vee E$ or $(D \vee E) \vee A \vee B \vee C$. To address this issue,
we adapted cvc5 to print an extra parameter to this tactic (and to others that suffered from the same problem),
which is a natural number corresponding to the index of the last proposition in the clause from the
point of view of the SMT solver. Therefore, for the example we just described, it would print
\texttt{pull pf, 4, 4} to indicate that it wants a proof for $(D \vee E) \vee A \vee B \vee C$ and
\texttt{pull pf, 4, 5} to indicate that it wants a proof for $E \vee A \vee B \vee C \vee D$.

\subsection*{PermutateClause\\\normalsize{Rule Statement:}}
\[
  \infer[]{P_{perm(1)} \vee \cdots \vee P_{perm(n)}}{P_{1} \vee \cdots \vee P_{n} \mid perm, s}
\]

Given the proof \texttt{pf} of a clause, a permutation \texttt{perm} and the index \texttt{s} of the last
proposition in the clause, \texttt{permutateClause pf, perm, s} provides a proof for the same clause, with
the propositions permutated according to \texttt{p}. This is the first tactic that matches a rule used by
cvc5.

Since we have an working implementation of \texttt{pull}, we can write a tactic matching
this rule using a relatively straightforward approach. We simply iterate through the permutation in
reverse order, and, for each index \texttt{i} we go through, we run the \texttt{pull} tactic
with $P_{perm(i)}$ as the argument. With this strategy, the last term we will bring to the first position is
$P_{perm(1)}$, therefore, the final clause we will produce will have the correct element in the first position.
Similarly, the second to last element we will bring to the first
position is $P_{perm(2)}$. After pulling it, we will bring another term to the first position ($P_{perm(1)}$), which will make $P_{perm(2)}$
end up in the second position, as required. By extending this reasoning to all the terms in the clause,
we can conclude that each one of them will be placed in the right position. Notice that the index \texttt{s} of
the last proposition does \textit{not} change during this process, so we can always use \texttt{s} as an argument
for \texttt{pull}.

\tom{I am wondering whether I put here the code of the core functionality of this tactic, like I did for groupClause}

The following snippet shows an example of usage of this tactic:

\begin{minted}{lean}
  theorem perm1 :
      A ∨ B ∨ C ∨ (D ∨ E ∨ F) → (D ∨ E ∨ F) ∨ B ∨ C ∨ A := by
    intro h
    permutateClause h, [3, 1, 2, 0], 3
\end{minted}

An essential observation is that, while proving the theorem corresponding to this rule appears to be a
challenging task, the implementation of the tactic was notably compact and uncomplicated, consisting of fewer
than 60 lines (excluding the source code of \texttt{pull}).


\subsection*{Resolution\\\normalsize{Rule Statement:}}
\[
  \infer[]{P_{1} \vee \cdots \vee P_{i - 1} \vee P_{i + 1} \vee \cdots \vee P_{n} \vee Q_{1} \vee \cdots \vee Q_{j - 1} \vee Q_{j + 1} \vee \cdots \vee Q_{m}}{P_{1} \vee \cdots \vee P_{i - 1} \vee A \vee P_{i + 1} \vee \cdots \vee P_{n}, Q_{1} \vee \cdots \vee Q_{j - 1} \vee \neg A \vee Q_{j + 1} \vee \cdots \vee Q_{m}, \mid A}
\]

Given two proofs of clauses, \texttt{pfP} and \texttt{pfQ} and a proposition \texttt{A}
(also known as the \textit{pivot}) such that
\texttt{A} is an element of the first clause and \texttt{¬ A} is an element of the second clause, this tactic produces a proof for the clause composed by the concatenation
of the two, removing the pivot from the first and the negation of the pivot from the second. If there are multiple instances of the pivot in the first clause, it removes
the first one. Similarly, if there are multiple instances of the negation of the pivot
in the second clause, it also removes the first one. We will need four new theorems
to implement the resolution tactic:

\begin{itemize}
  \item \mintinline{lean}{resolutionSpecialCase1 {A B C : Prop} : A ∨ B → ¬ A ∨ C → B ∨ C}
  \item \mintinline{lean}{resolutionSpecialCase2 {A B : Prop} : A ∨ B → ¬ A → B}
  \item \mintinline{lean}{resolutionSpecialCase3 {A C : Prop} : A → ¬ A ∨ C → C}
  \item \mintinline{lean}{resolutionSpecialCase4 {A : Prop} : A → ¬ A → False}
\end{itemize}

First, we apply \texttt{pull} to \texttt{pfP} to bring the first occurence of \texttt{A} to the first position. This will result
in a proof \texttt{pfP'} of the clause:

\begin{center}
  $A \vee P_{1} \vee \cdots \vee P_{i - 1} \vee P_{i + 1} \vee \cdots \vee P_{n}$
\end{center}

Next, we do the same at \texttt{pfQ}, bringing the negation of the pivot to the first position. We will obtain a proof \texttt{pfQ'} of
the clause:

\begin{center}
  $\neg A \vee Q_{1} \vee \cdots \vee Q_{j - 1} \vee Q_{j + 1} \vee \cdots \vee Q_{m}$
\end{center}

Now, we can apply one of the \texttt{resolutionSpecialCase} theorems to \texttt{pfP'} and \texttt{pfQ'}. We decide which theorem
to apply based on whether or not each clause has other terms apart from the pivot. If both clauses have other terms (i.e., $n > 0$ and
$m > 0$) we apply \texttt{resolutionSpecialCase1}, instantiating \texttt{B} to $P_{1} \vee \cdots \vee P_{i - 1} \vee P_{i + 1} \vee \cdots \vee P_{n}$ and \texttt{C} to $Q_{1} \vee \cdots \vee Q_{j - 1} \vee Q_{j + 1} \vee \cdots \vee Q_{m}$. If the second clause consists of only the negation of the pivot and the first one has other terms, we apply \texttt{resolutionSpecialCase2}. If the first clause consists of only the pivot and the second one has other terms, we apply \texttt{resolutionSpecialCase3}. If both clauses consists of a single element, we apply \texttt{resolutionSpecialCase4}, In this case, the tactic will produce a proof of \texttt{False}, which is the way we represent the empty clause.

Notice that, if we apply \texttt{resolutionSpecialCase1} and the first clause had more than 1 element
apart from the pivot, the term we will get is not exactly the required one. Its type will have the
propositions from the first clause parenthesized, i.e., it will have the following form:

\begin{center}
  $(P_{1} \vee \cdots \vee P_{n}) \vee Q_{1} \vee \cdots \vee Q_{m}$
\end{center}

We fix this issue with the tactic \texttt{ungroupClausePrefix}, which was mentioned before.

Since this tactic involves two input clauses, we need to have two parameters corresponding to
the indices of the last propositions in them. Also, the original rule used by cvc5 has another
boolean parameter, \textit{pol}. If pol is set to true, then the semantics of the rule match
exactly the tactic we described. If pol is set to false, the rule expects to find the pivot
negated in the first clause and not negated in the second. We have implemented a separate
tactic for this case. The function that implements the core functionality of both tactics is
the same.

The following snippet shows one example of usage of each tactic. \texttt{R1} corresponds to
the rule with pol set to true, and \texttt{R2} corresponds to the rule with pol set to false.
The last parameter of the tactic is a list with two elements, corresponding to the indices
of the last propositions in each clause.

\begin{minted}{lean}
  theorem res1 : A ∨ B ∨ C ∨ D → E ∨ ¬ B → A ∨ (C ∨ D) ∨ E := by
    intros h₁ h₂
    R1 h₁, h₂, B, [2, 1]

  theorem res2 : ¬ A → B ∨ A ∨ C → B ∨ C := by
    intros h₁ h₂
    R2 h₁, h₂, A, [0, 2]
\end{minted}


\subsection*{Factor\\\normalsize{Rule Statement:}}
\[
  \infer[]{removeDuplicates(P_{1} \vee \cdots \vee P_{n})}{P_{1} \vee \cdots \vee P_{n} \mid -}
\]

\subsection*{SumBounds\\\normalsize{Rule Statement:}}
\[
  \infer[]{\sum_{i = 1}^{n} a_{i} \bowtie^{*} \sum_{i = 1}^{n} b_{i}}{\bigwedge_{i = 1}^{n} a_{i} \bowtie_{i} b_{i}}
\]

\subsection*{MulPosNeg\\\normalsize{Rule Statement:}}
% \[
%   \infer[]{}{}
% \]


% \subsection{MulPosNeg}

% \subsection{TightBounds}


% TODO: put this in an appendix
\begin{table}[]\label{tab:rules}
\centering
\begin{tabular}{ l l l }
\toprule
Name        & Statement & Implementation \\ \midrule
NotImplies1 & \texttt{Not (p -> q) -> p}      & theorem        \\ \midrule
NotImplies2 & blah      & theorem        \\ \midrule
EquivElim1  & blah      & theorem        \\ \midrule
EquivElim2  & blah      & theorem        \\ \midrule
NotEquivElim1  & blah      & theorem        \\ \midrule
NotEquivElim2  & blah      & theorem        \\ \midrule
ImpliesElim & blah      & theorem        \\ \bottomrule
\end{tabular}
\caption{Rules from cvc5's proof calculus}
\end{table}


% proof of $P_{i - 1} \vee P_{i} \vee \cdots \vee P_{n} \rightarrow (P_{i - 1} \vee P_{i}) \vee \cdots \vee P_{n}$, together with \texttt{congOrLeft} to surpass
% the propositions to the left of $P_{i - 1}$. We need one application of \texttt{congOrLeft}
% for each proposition to the left of $P_{i - 1}$. For instance, if:
% \begin{itemize}
%   \item \textbf{i = 2} our term will be \texttt{orAssoc}
%   \item \textbf{i = 3} our term will be \texttt{congOrLeft orAssoc}
%   \item \textbf{i = 4} our term will be \texttt{congOrLeft (congOrLeft orAssoc)}
% \end{itemize}


% The idea is to use \texttt{congOrLeft} to surpass the propositions to the left of $P_{i - 1}$ together with \texttt{orAssoc} instantiating \texttt{A} to $P_{i - 1}$, \texttt{B} to $P_{i}$ and \texttt{C} to $P_{i + 1} \vee \cdots \vee
% P_{n}$, which will yield a proof of $P_{i - 1} \vee P_{i} \vee \cdots \vee P_{n} \rightarrow (P_{i - 1} \vee P_{i}) \vee \cdots \vee P_{n}$.


% We cannot directly apply it to $h$ since there are potentially other terms to the left of $P_{i - 1}$.
% To solve this problem, we use the theorem \texttt{congOrLeft} setting \texttt{hyp} to the application of \texttt{orAssoc} that we just described.
% Since the first $i - 2$ propositions are not grouped, we cannot instantiate \texttt{C} to $P_{i - 1} \vee \cdots \vee P_{i - 2}$.
% Instead, we set \texttt{C} to $P_{i - 2}$, which will yield a proof \texttt{h₂} of $P_{i - 2} \vee P_{i - 1} \vee P_{i} \vee \cdots \vee P_{n} \rightarrow P_{i - 2} \vee (P_{i - 1} \vee P_{i}) \vee \cdots \vee P_{n}$. Now we repeat the process applying \texttt{congOrLeft} with \texttt{C} instantiated to $P_{i - 3}$ (if it exists) and \texttt{hyp} to \texttt{h₂}. We keep going until we set \texttt{C} to $P_{1}$. We will then obtain a term of the form \texttt{congOrLeft (congOrLeft \ldots (congOrLeft orAssoc)\ldots)} (with $i - 2$ applications of \texttt{congOrLeft}), which, when applied to \texttt{h}, will prove $P_{1} \vee \cdots \vee (P_{i - 1} \vee P_{i}) \vee \cdots \vee P_{n}$.


% One detail that has to be considered while implementing this tactic is that the index of the last proposition
% may change when we pull a term. For instance, the index of the last proposition of the clause
% $A \vee B \vee (C \vee D) \vee E$ is $4$. If we pull $E$ in this clause, we will get
% $E \vee A \vee B \vee (C \vee D)$, which has $3$ as this index. If this happens,
% the new index will always be the original length of the clause minus the length
% of the second to last proposition in the current clause (since it will become the last proposition).
% While executing the procedure we described in the last paragraph, we need to always keep track of the
% current index of the last proposition, as the tactic pull requires it as an argument.

% \begin{figure}[t]
% % \textbf{Input:} $\psi$, a PL formula\\
% % \textbf{Output:} \textit{true} or \textit{false}, depending whether $\psi$ is satisfiable
% \begin{algorithmic}[1]
% \Function{PermutateClauseCore}{$pf$, $perm$, $s$}
%   \State $clause \gets $ \Call{InferType}{$pf$}
%   \State $lenClause \gets $ \Call{getLength}{$clause$}
%   \For{$i \gets n \Downto 1$}
%   \If{$perm_{i} = s$}
%     \State $currentClause \gets$ \Call{InferType}{pf}
%     \State $lenSecondLast \gets $ \Call{GetLength}{$currentClause_{s - 1}$}
%     \State $pf \gets$ \Call{PullCore}{$pf$, $perm_{i}$, $s$}
%     \State $s \gets lenSecondLast - lenClause$
%   \Else
%     \State $pf \gets$ \Call{PullCore}{$pf$, $perm_{i}$, $s$}
%   \EndIf
%   \EndFor
%   \State \Return~$pf$
% \EndFunction
% \end{algorithmic}
% \caption{Implementation of the tactic PermutateClause}~\label{permClause}
% \end{figure}
